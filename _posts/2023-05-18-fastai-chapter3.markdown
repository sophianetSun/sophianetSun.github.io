---
layout: post
title: "fastai와 파이토치가 만나 꽃피운 딥러닝 3장"
date: 2023-05-18 01:00:00 +0900
categories: ml
---

[Deep Learning for Coders with fastai & PyTorch][fastai]의 3장이다.

3장까지는 기술적으로 상세한 내용보다는 개론적인 내용을 소개하고 있다. 특히 3장 데이터 윤리는 수학이나, 코딩에 대한 내용은 전혀 나오지 않고, 윤리 철학적인 내용을 다루고 있다. _주 저자 중 한명인 제레미의 전공이었던 부분이다. fast.ai 공동설립장이자 샌프란시스코 대학 응용 데이터 윤리 센터의 창립 이사인 레이철 토마스 박사와 함께 집필했다고 한다._

ChatGPT가 요즘 엄청나게 뜨거운 주제가 되면서, 앞 장에서도 이야기 했듯이 언어모델 오용의 위험성 등 머신러닝(딥러닝)의 기술의 이용에 대해 여러가지 철학적 논의가 대두되고 있다. 기계(컴퓨터/AI)가 인간 같이 마음과 이성을 가질 수 있는가? 하는 좀 먼 주제의 이야기는 여기서는 차치하고, 좀 더 현실적이고 직접적인 학습에 사용되는 데이터와 모델에 활용 결과의 실제 적용에서 윤리적인 부분에 대해 이야기 하고 있다. _이 주제에 대해서는 노벨상을 탄 물리학자 로저 펜로즈의 [황제의 새마음][emperors_new_mind]에서 깊이 다루고 있으니 한번 탐독해 볼 만하다_

이 장의 질문은 다음과 같다.

1. 윤리에 '올바른 정답'이 있을까요?

윤리 _ethics_ 는 옳고 그름, 선악, 권리 등 많은 것들에 대해 이야기 하는데, 이는 너무 복잡하고 상황에 따라 다르기 대문에 '올바른' 정답을 말할 수 없다. 책에서 한 가지 비유를 든 것은 윤리란 일종의 근육과도 같다고 얘기하고 있다. 근육은 쓰지 않으면 퇴화하고, 단련하면 더더욱 강건해 진다. 이처럼 윤리도 지속적인 계발과 단련이 필요하다고 말하고 있다. 참 좋은 비유라고 생각되는게 근육도 상황에 따라 어떤 근육이 정답이라고 말할 수 없다. 멋진 몸매를 위한 근육, 운동선수의 폭발적인 힘을 내기 위한 근육, 건강한 일상생활을 위한 근육 등 상황에 따라 다르기 때문에 무엇이 정답이라고 얘기할 수 없는 것은 마찬가지 일 것이다.

2. 윤리적 질문 고려할 때 배경이 다른 사람들과 일하면 어떤 도움이 되나요?

배경이 다른 사람들과 일하게 되면 내가 경험하지 못한, 생각하지 못한 관점을 경험할 수 있기 때문에 여러가지 '근육 형성' 활동에 유용하다.

3. 나치 독일에서 IBM의 역할은 무엇이었나요? 회사가 참여한 이유는 무엇인가요? 또 노동자들이 참여한 이유는 무엇일까요?

나치 독일에서 IBM은 유대인을 포함한 여러 그룹의 대규모 학살 기록을 추적하는 데이터 테이블 상품을 나치에 공급했다. 회사는 이를 통해 어마어마한 수익을 얻게 되고, 이를 바탕으로 막대한 기술력을 가질 수 있게 되어 시장 지배력을 강화할 수 있기 때문이다. 노동자(기술자)들은 목적을 생각하지 않고 수단을 중시했기에, 유대인 학살이라는 이슈보다는 자신에게 주어진 업무에만 최선을 다했기 때문이다.

4. 폭스바겐 디젤 스캔들에서 수감된 첫 번째 사람의 역할은 무엇이었나요?

회사의 지시를 받아 업무를 처리한 엔지니어인 제임스 리앙<sup>James Liang</sup>

5. 캘리포니아 법 집행관이 관리하는 갱단 용의자 데이터베이스의 문제점은 무엇이었나요?

캘리포니아 법률 집행원이 관리하는 데이터베이스에는 오류로 가득차 있었다. 한 살이 되기 전 아기 42명이 포함되었고 그중 28명은 범죄 죅 구성원으로 인정되었다는 표시도 얻었다.

6. 구글 직원이 프로그래밍하지 않았음에도, 유튜브의 추천 알고리즘이 옷을 덜 입은 아동의 동영상을 소아 성애자에게 추천한 이유는 무엇인가요?

최적화 지표를 가진 알고리즘은 극단적인 상황으로 이어지는 경향이 있으며, 피드백 루프를 통해 옷을 덜 입은 아동을 포함한 영상을 소아성애자용 재생 목록으로 선별하기 시작했다.

7. 평가지표 중심성의 문제는 무엇인가요?

평가지표 최적화 작업에만 몰두하면 작업의 결과물이 어떻게 이용되는지, 활용되는지 놓칠 수 있다. 결과물이 나쁘게 사용되거나 사회와 환경에 안좋은 결과를 낼 수도 있는데, 이런 전체적인 과정을 놓치고 단순히 주어진 평가지표만을 만족하는 작업만을 진행한다면 작업이 올바른 방식으로 사용되도록 할 수 없을 것이다.

8. 밋업이 기술 모임 추천 시스템에 성별을 포함하지 않은 이유는 무엇인가요?

남성이 여성보다 기술 모임에 더 많은 관심을 보이기 때문에 밋업의 알고리즘이 여성에게 기술 모임을 덜 추천해서 여성이 기술 모임을 알아내 참석할 기회를 덜 주기 때문.

9. 수레시와 구탁이 말한 머신러닝의 여섯 가지 유형의 편향은 무엇인가요?

> 1. 역사적 편향
> 2. 대표성 편향
> 3. 측정 편향
> 4. 검증 편향
> 5. 종합 편향
> 6. 배포 편향

10. 미국의 역사적 인종 편향의 예를 두 가지 들어보세요.

- 검사 결과가 같아도, 의사는 백인 보다 훨씬 적은 확률로 흑인 환자에게 수술을 권함.
- 중고차 흥정 시 흑인에게 제시된 초기 가격이 700달러 더 높고, 할인도 훨씬 적게 받음.
- 아파트 임대 광고에 흑인 이름으로 응답하면 백인 이름보다 회신율이 낮음.
- 백인으로만 구성된 배심원은 백인보다 흑인 피고인을 더 높은 확률로 유죄 판결했지만, 배심원에 흑인이 한 명이라도 포함되면 인종에 상관없이 같은 비율로 유죄 판결을 받음.

11. 이미지넷을 구성하는 이미지는 주로 어디서 수집되었나요?

미국에서 45.4%에 비율로 수집됨.

12. [Does Machine Learning Automate Moral Hazard and Error?]논문에서 부비동염이 뇌졸중의 예측변수인 이유를 무엇이라고 설명하나요?

측정 편향으로 의료서비스를 받을 수 있는, 의사를 자주 찾는 사람들의 증상들에게 수집된 정보였기 때문

13. 대표성 편향이란 무엇인가요?

단순한 모델이 편향을 증폭 시키는 현상.

14. 결정을 내리는 데 사용되는 기계와 사람은 어떻게 다른가요?

기계는 피드백 루프를 만들 수 있어 약간의 편향이라도 기하급수적으로 빠르게 증가할 수 있다.

15. 허위 정보와 '가짜 뉴스'는 같은 의미 인가요?

허위 정보는 가짜 뉴스를 포함하는 개념으로 설명될 수 있다. 허위 정보에는 진실에 기반을 두기도 하고, 맥락을 약간 벗어난 절반의 진실을 포함하고 있기도 하기 때문에 가짜라고 단순하게 통칭하기에는 어려운 부분이 있다.

16. 자동 생성된 텍스트로 퍼지는 허위 정보가 특히 심각한 문제인 이유는 무엇인가요?

만드는데 비용이 저렴하고, 정확하게 정보를 위조할 수 있게 되어, 사람들이 쉽게 속게 되고 이를 통해 민주주의, 보안 사회에 재앙을 초래할 수 있기 때문.

17. 마쿨라 센터에서 설명하는 다섯 유형의 윤리적 렌즈를 무엇인가요?

마쿨라 센터의 '기술 및 공학 실무의 개념적 프레임워크([https://oreil.ly/QnRTt](https://oreil.ly/QnRTt))' 자료에 따르면

- 권리적 접근법: 어떤 선택이 모든 이해관계자의 권리를 가장 잘 존중하나요?
- 정의적 접근법: 어떤 선택이 사람들을 동등하게 또는 균형적으로 대하나요?
- 실용주의적 접근법: 어떤 선택이 가장 좋은 결과물을 가져오고 피해를 최소화하나요?
- 공동체에 적합한 접근법: 어떤 선택이 일부 구성원뿐만 아니라 지역사회 전체에 가장 적합하나요?
- 선행적 접근법: 어떤 선택이 여러분의 양심과 가치관에 더 부합하나요?

18. 데이터 윤리 문제 해결에 정책적으로 적합한 도구는 어디에 있나요?

단순한 해결칙은 존재하지 않는다. 적합한 규제를 만들기 위해서는 여론이 뒤따라 주어야 하고, 이러한 것들을 위해서는 개인과 사회, 기업이 모두 윤리적인 행동이 필요하기 때문이다.

추가 연구

1. [What Happens When an Algorithm Cuts Your Healthcare](https://oreil.ly/5Ziok) 기사를 읽어보세요. 이와 같은 문제를 앞으로 어떻게 방지할 수 있을까요?

유튜브의 추천 시스템과 사회적 영향을 자세히 조사해보세요. 추천 시스템에는 항상 부정적인 결과의 피드백 루프가 있을 수 밖에 없다고 생각하나요? 이를 피하라면 구글과 정부는 어떤 접근법을 취할 수 있을까요?

2. [Discrimination in Online Ad Delivery](https://oreil.ly/jgKpM) 논문을 읽어보세요. 스위니 박사에게 일어난 일을 구글이 책임져야 하낟고 생각하나요? 적절한 조치는 무엇일까요?

3. 팀에 여러 분야의 구성원이 있으면 부정적인 결과를 피하는 데 어떤 도움을 주나요?

4. [Does Machine Learning Automate Moral Hazard and Error?](https://oreil.ly/tLLOf) 논문을 읽어보세요. 이 논문이 지적한 문제에 대해 어떤 조치를 취해야 한다고 생각하나요?

5. [How Will We Prevent AI-Based Forgery?](https://oreil.ly/6MQe4) 기사를 읽어보세요. 에지오니가 제안한 접근법이 효과가 있다고 생각하나요? 그 이유는 무엇인가요?

6. 3.4.1에 제시된 일련의 질문에 답해보세요.

7. 여러분의 팀이 더 다양한 배경의 구성원을 수용할 수 있는지 고려해보세요. 어떤 접근법이 도움이 될까요?

[fastai]: https://course.fast.ai/
[emperors_new_mind]: https://en.wikipedia.org/wiki/The_Emperor%27s_New_Mind
